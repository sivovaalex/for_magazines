{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: to apply machine learning methods to predict atmospheric pollution from the following data:\n",
    "        https://www.kaggle.com/unitednations/international-greenhouse-gas-emissions\n",
    "using the decision tree and the Spark large database tool (PySpark for python)\n",
    "\n",
    "Цель: применить методы машинного обучения для предсказывания загрязнений атмосферы по данным:\n",
    "        https://www.kaggle.com/unitednations/international-greenhouse-gas-emissions\n",
    "используя дерево решений и инструмент для работы с большими базами данных Spark (PySpark для python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T10:42:56.292020Z",
     "start_time": "2020-09-16T10:42:55.445135Z"
    }
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "#портируем необходимые библиотеки\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "#other types of regression models\n",
    "#можно использовать и другие виды регрессии\n",
    "#from pyspark.ml.regression import LinearRegression\n",
    "#from pyspark.ml.regression import RandomForestRegressor\n",
    "#from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "#from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T10:43:46.785474Z",
     "start_time": "2020-09-16T10:43:46.778230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.104:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f270fc6da90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create spark session\n",
    "#создаём спарк сессею\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T10:43:55.699083Z",
     "start_time": "2020-09-16T10:43:51.127006Z"
    }
   },
   "outputs": [],
   "source": [
    "#load .csv data from path_csv\n",
    "#загружаем данные формата .csv из path_csv\n",
    "path_csv = 'greenhouse_gas_inventory_data_data.csv'\n",
    "data = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"delimiter\", \",\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .load(path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8406"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of rows in the dataset\n",
    "#количество строк данных\n",
    "data.select('year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T10:43:57.789910Z",
     "start_time": "2020-09-16T10:43:55.702725Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+----------------+--------------------+\n",
      "|country_or_area|year|           value|            category|\n",
      "+---------------+----+----------------+--------------------+\n",
      "|      Australia|2014|393126.946994288|carbon_dioxide_co...|\n",
      "|      Australia|2013| 396913.93653029|carbon_dioxide_co...|\n",
      "|      Australia|2012|  406462.8477036|carbon_dioxide_co...|\n",
      "|      Australia|2011|403705.528313991|carbon_dioxide_co...|\n",
      "|      Australia|2010|406200.993184341|carbon_dioxide_co...|\n",
      "|      Australia|2009| 408448.47899963|carbon_dioxide_co...|\n",
      "|      Australia|2008|404237.828214077|carbon_dioxide_co...|\n",
      "|      Australia|2007|398816.453543549|carbon_dioxide_co...|\n",
      "|      Australia|2006|391134.100909449|carbon_dioxide_co...|\n",
      "|      Australia|2005|385581.132806466|carbon_dioxide_co...|\n",
      "|      Australia|2004|381519.261592783|carbon_dioxide_co...|\n",
      "|      Australia|2003|368345.977425107|carbon_dioxide_co...|\n",
      "|      Australia|2002|361861.387896028|carbon_dioxide_co...|\n",
      "|      Australia|2001|357653.329899303|carbon_dioxide_co...|\n",
      "|      Australia|2000|349885.433108928|carbon_dioxide_co...|\n",
      "|      Australia|1999|343713.906947774|carbon_dioxide_co...|\n",
      "|      Australia|1998|334328.142646602|carbon_dioxide_co...|\n",
      "|      Australia|1997|320439.116819391|carbon_dioxide_co...|\n",
      "|      Australia|1996|311914.819824229|carbon_dioxide_co...|\n",
      "|      Australia|1995|305162.543548735|carbon_dioxide_co...|\n",
      "+---------------+----+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show part of data\n",
    "#посмотрим на часть данных\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T10:44:00.464743Z",
     "start_time": "2020-09-16T10:43:58.914383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "|category                                                                                                      |\n",
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "|nitrogen_trifluoride_nf3_emissions_in_kilotonne_co2_equivalent                                                |\n",
      "|unspecified_mix_of_hydrofluorocarbons_hfcs_and_perfluorocarbons_pfcs_emissions_in_kilotonne_co2_equivalent    |\n",
      "|methane_ch4_emissions_without_land_use_land_use_change_and_forestry_lulucf_in_kilotonne_co2_equivalent        |\n",
      "|nitrous_oxide_n2o_emissions_without_land_use_land_use_change_and_forestry_lulucf_in_kilotonne_co2_equivalent  |\n",
      "|greenhouse_gas_ghgs_emissions_including_indirect_co2_without_lulucf_in_kilotonne_co2_equivalent               |\n",
      "|greenhouse_gas_ghgs_emissions_without_land_use_land_use_change_and_forestry_lulucf_in_kilotonne_co2_equivalent|\n",
      "|carbon_dioxide_co2_emissions_without_land_use_land_use_change_and_forestry_lulucf_in_kilotonne_co2_equivalent |\n",
      "|sulphur_hexafluoride_sf6_emissions_in_kilotonne_co2_equivalent                                                |\n",
      "|hydrofluorocarbons_hfcs_emissions_in_kilotonne_co2_equivalent                                                 |\n",
      "|perfluorocarbons_pfcs_emissions_in_kilotonne_co2_equivalent                                                   |\n",
      "+--------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show all varients of category column values\n",
    "#посмотрим на варианты значений колонки category\n",
    "data.select(\"category\").distinct().show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T10:44:12.764878Z",
     "start_time": "2020-09-16T10:44:12.741245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_or_area: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show types of columns\n",
    "#посмотрим на типы всех наших колонок\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T11:32:36.582917Z",
     "start_time": "2020-09-16T11:32:36.539359Z"
    }
   },
   "outputs": [],
   "source": [
    "#value is dependent and predicted  - label\n",
    "#value - это зависимая и предсказываемая переменная - метка\n",
    "stages = []\n",
    "label_stringIdx = StringIndexer(inputCol = 'value', outputCol = 'label', handleInvalid = 'keep')\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "#depend on categorical columns: country and types of emission\n",
    "#зависит от категориаьных колонок: страны и категории загрязнения\n",
    "categoricalColumns = ['country_or_area', 'category']\n",
    "for categoricalCol in categoricalColumns:\n",
    "    #convert categorical columns to binary vectors through string conventer\n",
    "    #преобразование категориальных колонок в бинарные вектора благодаря строковому преобразователю\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol,\n",
    "                                  outputCol = categoricalCol + 'Index',\n",
    "                                  handleInvalid = 'keep')\n",
    "    encoder = OneHotEncoder(inputCol=stringIndexer.getOutputCol(),\n",
    "                            outputCol=categoricalCol + \"classVec\")\n",
    "    stages += [stringIndexer, encoder]\n",
    "\n",
    "#depend on numeric column: year\n",
    "#зависит от численной колонки: года\n",
    "numericCols = ['year']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "#convert multiple columns into a vector column - features\n",
    "#преобразование нескольких колонок в вектор-колонку - признаки\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T11:32:45.249367Z",
     "start_time": "2020-09-16T11:32:45.225568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "#делим данные на обучающую и тестовую выборки (30% тестовая)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# еrain a GBT ( gradient boosting tree regression) model\n",
    "#тренируем модель (градиентного регрессионого дерева бустинга)\n",
    "gbt = GBTRegressor(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "stages += [gbt]\n",
    "\n",
    "# give a plan (stages) model training \n",
    "# задаем план stages для обучения модели \n",
    "pipeline = Pipeline(stages=stages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T11:33:15.015269Z",
     "start_time": "2020-09-16T11:32:47.416899Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "# тренируем модель\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# make predictions on test dataset\n",
    "# делаем предсказания на тестовой выборке\n",
    "predictions = model.transform(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T11:33:47.808400Z",
     "start_time": "2020-09-16T11:33:47.355799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 2801.75\n",
      "GBTRegressionModel: uid=GBTRegressor_a6fe876dd0b5, numTrees=10, numFeatures=54\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "# выбираем предсказанное и истинное значение и считаем ошибку\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "gbtModel = model.stages[-1]\n",
    "print(gbtModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbt 2717.59\n",
    "#lin_regr 2737.69\n",
    "#rand_for_regr 2751.47\n",
    "#dec_tree_regr 2709.51\n",
    "#gen_lin_regr 2723.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T11:34:45.920886Z",
     "start_time": "2020-09-16T11:34:40.264718Z"
    }
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "#сохраняем модель\n",
    "pipeline.write().overwrite().save('model/gbtregr_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "#загружаем модель для работы после обучения\n",
    "load_model = pipeline.read().load('model/gbtregr_model_1') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                               Conclusion\n",
    "                                                 Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the error turned out to be very large, however, the goal to improve the methodology of working in PySpark on the example of pollution data in different countries in the period from 1990-2017 with several columns of different types was completed. such an error value may be associated with a small dataset (only 8.4 K) and the use of solving trees for regression problems\n",
    "\n",
    "ошибка получилась очень большой, однако, цель разбаботать методику работы в PySpark \n",
    "на примере данных загрязнений в разных странах в перод времени с 1990-2017 \n",
    "с несколькими колонками разных типов выполнена.\n",
    "подобная величина ошибки может быть связана с маленьким датасетом (всего 8,4 к)\n",
    "и применением решаюшщих деревьев для задач регрессии"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
